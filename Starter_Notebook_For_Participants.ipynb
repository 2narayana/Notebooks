{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEFmR5J_COHU"
   },
   "source": [
    "## Import Required Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YosGM4uOCOHZ"
   },
   "outputs": [],
   "source": [
    "## change it to the unzip path of the downloaded dataset..\n",
    "data_folder = r'/Users/anurag/Downloads/movie genre classification/Scripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MGrGh94COHh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Files : 2827\n"
     ]
    }
   ],
   "source": [
    "all_files = os.listdir(data_folder)\n",
    "print('Total Number of Files :', len(all_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Train Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>File_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>file_2180.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>file_693.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Drama</td>\n",
       "      <td>file_2469.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Drama</td>\n",
       "      <td>file_2542.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>file_378.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1973</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>file_1930.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1974</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>file_1821.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>file_350.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1976</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>file_1933.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1977</td>\n",
       "      <td>Horror</td>\n",
       "      <td>file_1210.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1978 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Genre      File_Name\n",
       "0      Fantasy  file_2180.txt\n",
       "1       Comedy   file_693.txt\n",
       "2        Drama  file_2469.txt\n",
       "3        Drama  file_2542.txt\n",
       "4       Sci-Fi   file_378.txt\n",
       "...        ...            ...\n",
       "1973  Thriller  file_1930.txt\n",
       "1974  Thriller  file_1821.txt\n",
       "1975    Sci-Fi   file_350.txt\n",
       "1976  Thriller  file_1933.txt\n",
       "1977    Horror  file_1210.txt\n",
       "\n",
       "[1978 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('Train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>File_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>file_2300.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>file_809.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Action</td>\n",
       "      <td>file_1383.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>file_983.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>file_1713.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>844</td>\n",
       "      <td>Drama</td>\n",
       "      <td>file_2474.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>file_863.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>War</td>\n",
       "      <td>file_1547.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>847</td>\n",
       "      <td>Action</td>\n",
       "      <td>file_1292.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>848</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>file_1910.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>849 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Genre      File_Name\n",
       "0        Drama  file_2300.txt\n",
       "1       Comedy   file_809.txt\n",
       "2       Action  file_1383.txt\n",
       "3    Adventure   file_983.txt\n",
       "4     Thriller  file_1713.txt\n",
       "..         ...            ...\n",
       "844      Drama  file_2474.txt\n",
       "845     Comedy   file_863.txt\n",
       "846        War  file_1547.txt\n",
       "847     Action  file_1292.txt\n",
       "848   Thriller  file_1910.txt\n",
       "\n",
       "[849 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('Our_test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's read the text scripts in the train and test dataframes..\n",
    "\n",
    "train_df['Script'] = [open(data_folder + os.sep + file, \"r\").read() for file in train_df['File_Name']]\n",
    "test_df['Script'] = [open(data_folder + os.sep + file, \"r\").read() for file in test_df['File_Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets look at a script file after Reading.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b><!--\n",
      "\n",
      "</b>if (window!= top)\n",
      "\n",
      "top.location.href=location.href\n",
      "\n",
      "<b>// -->\n",
      "\n",
      "</b>\n",
      "\n",
      "The Abyss - by James Cameron \n",
      "\n",
      "                                  THE ABYSS\n",
      "\n",
      "                            AN ORIGINAL SCREENPLAY\n",
      "\n",
      "                                      BY\n",
      "\n",
      "                                JAMES CAMERON\n",
      "\n",
      "                               August 2, 1988\n",
      "\n",
      "                             Director's Revision\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "                                  THE ABYSS\n",
      "\n",
      "OMITTED                                                                 1\n",
      "\n",
      "OMITTED                                                                 2\n",
      "\n",
      "TITLE: THE ABYSS -- ON BLACK, DISSOLVING TO COBALT BLUE\n",
      "\n",
      "EXT. OCEAN/UNDERWATER -- DAY                                            3\n",
      "\n",
      "Blue, deep and featureless, the twilight of five hundred feet down.\n",
      "\n",
      "PROPELLER SOUND.  Materializing out of the blue limbo is the enormous but\n",
      "\n",
      "sleek form of an Ohio-class SSBN ballistic missile submarine.\n",
      "\n",
      "INT. U.S.S. MONTANA -- DAY                                              4\n",
      "\n",
      "In the attack center, darkened to womb-red, the crew's faces shine with sweat\n",
      "\n",
      "in the glow of their instruments.  The SKIPPER and his EXEC crowd around\n",
      "\n",
      "BARNES, the sonarman.\n",
      "\n",
      "                                CAPTAIN\n",
      "\n",
      "                Sixty knots?  No way, Barnes... the reds don't\n",
      "\n",
      "                have anything that fast.\n",
      "\n",
      "                                BARNES\n",
      "\n",
      "                Checked it twice, skipper.  It's a real unique\n",
      "\n",
      "                signature.  No cavitation, no reactor noise...\n",
      "\n",
      "                doesn't even sound like screws.\n",
      "\n",
      "He puts the signal onto a speaker and everyone in the attack room listens to\n",
      "\n",
      "the intruder's acoustic signature, a strange THRUMMING.  The captain studies\n",
      "\n",
      "the electronic position board, a graphic representation of the contours of\n",
      "\n",
      "the steep-walled canyon, a symbol for the Montana, and converging with it, an\n",
      "\n",
      "amorphous trace, representing the bogey.\n",
      "\n",
      "                                CAPTAIN\n",
      "\n",
      "                What the hell is it?\n",
      "\n",
      "                                EXEC\n",
      "\n",
      "                I'll tell you what it's not, it's not one of\n",
      "\n",
      "                ours.\n",
      "\n",
      "                                BARNES\n",
      "\n",
      "                Sir!  Contact changing heading to two-one-four,\n",
      "\n",
      "                diving.  Speed eighty knots!  Eighty knots!\n",
      "\n",
      "                                EXEC\n",
      "\n",
      "                Eighty knots...\n",
      "\n",
      "                                BARNES\n",
      "\n",
      "                Still diving, depth nine hundred feet.  Port\n",
      "\n",
      "                clearance to cliff wall, one hundred fifty feet.\n",
      "\n",
      "                                FRANK\n",
      "\n",
      "                           (simultaneously)\n",
      "\n",
      "                Still diving, depth nine hundred feet.  Port\n",
      "\n",
      "                clearance to cliff wall, one hundred fifty feet.\n",
      "\n",
      "Tension builds in the attack room as the Montana surges to intercept the\n",
      "\n",
      "intruder.  The exec tensely watches the vector-graphic readout for the side-\n",
      "\n",
      "scan sonar array.  The sub is running uncomfortably\n"
     ]
    }
   ],
   "source": [
    "#lets check one of the scripts..\n",
    "print(train_df['Script'][4][:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          KING KONG\n",
      "\n",
      "                                          Written by\n",
      "\n",
      "                        Fran Walsh, Philippa Boyens and Peter Jackson\n",
      "\n",
      "                                     Based on a Story by\n",
      "\n",
      "                             Merian C. Cooper and Edgar Wallace\n",
      "\n",
      "                                                                   1.\n",
      "\n",
      "          EXT. CENTRAL PARK - DAY\n",
      "\n",
      "          CLOSE ON: A scrawny MONKEY scratches.\n",
      "\n",
      "          ANGLES ON: Defeated, listless ANIMALS, in the bleak environs of a\n",
      "\n",
      "          dilapidated ZOO.\n",
      "\n",
      "          WIDER: It is CENTRAL PARK ZOO in depression era NEW YORK. The PARK\n",
      "\n",
      "          itself is like a GARBAGE DUMP, dotted with squalid SHANTY TOWNS.\n",
      "\n",
      "          Against these BLEAK IMAGES, the SOUND of a BRIGHT, BRASSY SONG\n",
      "\n",
      "          fades up: Al Jolson, singing \"I'm Sitting on Top of the World\".\n",
      "\n",
      "          The sky line of MANHATTAN rises in the background, a grim steaming\n",
      "\n",
      "          jungle on this cold FALL day.\n",
      "\n",
      "                                                        I\n",
      "\n",
      "          EXT. NY STREETS - DAY\n",
      "\n",
      "          LONG continues over:\n",
      "\n",
      "          IMAGES: The CROWDED STREETS of NEW YORK ... beneath the bustle is\n",
      "\n",
      "          a sense of despair.\n",
      "\n",
      "          LONG SOUP LINES snake along the STREETS.\n",
      "\n",
      "          The HUNGRY search through RUBBISH BINS for FOOD. SKYSCRAPERS rise\n",
      "\n",
      "          steadily upwards as more people are evicted from their homes.\n",
      "\n",
      "          HOMELESS sleep amid steaming VENTS and GARBAGE STREWN GUTTERS.\n",
      "\n",
      "                                                             Intercut:\n",
      "\n",
      "          INT. VAUDEVILLE THEATRE - NIGHT\n",
      "\n",
      "          SONG continues over:\n",
      "\n",
      "          I\n",
      "\n",
      "          SANNY, an old-time VAUDEVILLIAN, hurriedly fixes a large DROOPY\n",
      "\n",
      "          MOUSTACHE on to a YOUNG WOMAN'S TOP LIP ... this is ANN DARROW.\n",
      "\n",
      "          IMAGES: Weird and wonderful snatches of VAUDEVILLE ACTS follow ...\n",
      "\n",
      "          singers, jugglers, boxing ladies.\n",
      "\n",
      "          E\n",
      "\n",
      "                                                        Intercut with:\n",
      "\n",
      "          EXT. NY STREETS - DAY\n",
      "\n",
      "          The COLOR and MUSIC contrast with the SOUP LINES and SLUMPED\n",
      "\n",
      "          SHOULDERS of the REAL WORLD.\n",
      "\n",
      "          INT. VAUDEVILLE THEATRE - NIGHT\n",
      "\n",
      "          ANGLE ON: ANN on STAGE ... dressed as an ELEGANT GENT, she\n",
      "\n",
      "          launches into `I'm Just Wild About Harry' with HARRY, a larger-\n",
      "\n",
      "          than-life PERFORMER dressed in a FRILLY DRESS, BRASSY RED WIG and\n",
      "\n",
      "          FALSIES.\n",
      "\n",
      "                                                                   2.\n",
      "\n",
      "          MANNY's CHARACTER joins in ... SNEEZING LOUDLY and causing ANN to\n",
      "\n",
      "          take a SUDDEN PRAT FALL.\n",
      "\n",
      "           nd so the ROUTINE BUILDS ... ANN and HARRY singing and dancing\n",
      "\n",
      "          ... MANNY SNEEZING ... ANN falling.\n",
      "\n",
      "          The AUDIENCE look on with bored expressions on their faces. All\n",
      "\n",
      "          except ONE MAN at the BACK, who is LAUGHING HYSTERICALLY.\n",
      "\n",
      "          CLOSE ON: ANN throwing everything into her ACT ... SWEAT rolls\n",
      "\n",
      "          down her face ... she tries\n"
     ]
    }
   ],
   "source": [
    "print(test_df['Script'][4][:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "5Z6GyVjFD9aH",
    "outputId": "309eb172-19cc-40a4-e198-bc24dbf4d804"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drama        405\n",
       "Thriller     261\n",
       "Comedy       243\n",
       "Action       203\n",
       "Crime        141\n",
       "Romance      134\n",
       "Adventure    116\n",
       "Sci-Fi       109\n",
       "Horror       104\n",
       "Fantasy       79\n",
       "Mystery       75\n",
       "Family        27\n",
       "Animation     25\n",
       "War           18\n",
       "Musical       15\n",
       "Western        9\n",
       "Music          4\n",
       "Film-Noir      3\n",
       "Short          2\n",
       "Biography      2\n",
       "History        2\n",
       "Sport          1\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we notice that `genre == 'Sport'` has only 1 occurrence, Hence we can't stratify the split for validation data, if we use `Sport`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1859</td>\n",
       "      <td>Sport</td>\n",
       "      <td>file_922.txt</td>\n",
       "      <td>SPEED RACER\\n\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Genre     File_Name                                             Script\n",
       "1859  Sport  file_922.txt                                  SPEED RACER\\n\\..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['Genre'] == 'Sport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1977, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop(1859, axis=0)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LdCtl00oCOIZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/a5/703d93321f57048596217789be7c186304a33aff5b1c48c89597a546c65e/xgboost-1.0.2.tar.gz (821kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 874kB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/anurag/opt/anaconda3/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base pip-egg-info\n",
      "         cwd: /private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/\n",
      "    Complete output (83 lines):\n",
      "    ++ pwd\n",
      "    + oldpath=/private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost\n",
      "    + cd ./xgboost/\n",
      "    + mkdir -p build\n",
      "    + cd build\n",
      "    + cmake ..\n",
      "    -- The CXX compiler identification is unknown\n",
      "    -- The C compiler identification is unknown\n",
      "    -- Check for working CXX compiler: /usr/bin/c++\n",
      "    -- Check for working CXX compiler: /usr/bin/c++ -- broken\n",
      "    CMake Error at /usr/local/Cellar/cmake/3.16.4/share/cmake/Modules/CMakeTestCXXCompiler.cmake:53 (message):\n",
      "      The C++ compiler\n",
      "    \n",
      "        \"/usr/bin/c++\"\n",
      "    \n",
      "      is not able to compile a simple test program.\n",
      "    \n",
      "      It fails with the following output:\n",
      "    \n",
      "        Change Dir: /private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/xgboost/build/CMakeFiles/CMakeTmp\n",
      "    \n",
      "        Run Build Command(s):/usr/bin/make cmTC_92e81/fast && xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "      CMake will not be able to correctly generate this project.\n",
      "    Call Stack (most recent call first):\n",
      "      CMakeLists.txt:2 (project)\n",
      "    \n",
      "    \n",
      "    -- Configuring incomplete, errors occurred!\n",
      "    See also \"/private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/xgboost/build/CMakeFiles/CMakeOutput.log\".\n",
      "    See also \"/private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/xgboost/build/CMakeFiles/CMakeError.log\".\n",
      "    + echo -----------------------------\n",
      "    -----------------------------\n",
      "    + echo 'Building multi-thread xgboost failed'\n",
      "    Building multi-thread xgboost failed\n",
      "    + echo 'Start to build single-thread xgboost'\n",
      "    Start to build single-thread xgboost\n",
      "    + cmake .. -DUSE_OPENMP=0\n",
      "    -- The CXX compiler identification is unknown\n",
      "    -- The C compiler identification is unknown\n",
      "    -- Check for working CXX compiler: /usr/bin/c++\n",
      "    -- Check for working CXX compiler: /usr/bin/c++ -- broken\n",
      "    CMake Error at /usr/local/Cellar/cmake/3.16.4/share/cmake/Modules/CMakeTestCXXCompiler.cmake:53 (message):\n",
      "      The C++ compiler\n",
      "    \n",
      "        \"/usr/bin/c++\"\n",
      "    \n",
      "      is not able to compile a simple test program.\n",
      "    \n",
      "      It fails with the following output:\n",
      "    \n",
      "        Change Dir: /private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/xgboost/build/CMakeFiles/CMakeTmp\n",
      "    \n",
      "        Run Build Command(s):/usr/bin/make cmTC_e5f7b/fast && xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "      CMake will not be able to correctly generate this project.\n",
      "    Call Stack (most recent call first):\n",
      "      CMakeLists.txt:2 (project)\n",
      "    \n",
      "    \n",
      "    -- Configuring incomplete, errors occurred!\n",
      "    See also \"/private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/xgboost/build/CMakeFiles/CMakeOutput.log\".\n",
      "    See also \"/private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/xgboost/build/CMakeFiles/CMakeError.log\".\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/setup.py\", line 42, in <module>\n",
      "        LIB_PATH = libpath['find_lib_path']()\n",
      "      File \"/private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/xgboost/libpath.py\", line 50, in find_lib_path\n",
      "        'List of candidates:\\n' + ('\\n'.join(dll_path)))\n",
      "    XGBoostLibraryNotFound: Cannot find XGBoost Library in the candidate path, did you install compilers and run build.sh in root path?\n",
      "    List of candidates:\n",
      "    /private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/xgboost/libxgboost.dylib\n",
      "    /private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/xgboost/../../lib/libxgboost.dylib\n",
      "    /private/var/folders/54/j_0l_c55427fvv9sfj94g4sw0000gp/T/pip-install-f0m4pjgo/xgboost/xgboost/./lib/libxgboost.dylib\n",
      "    /Users/anurag/opt/anaconda3/xgboost/libxgboost.dylib\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: keras in /Users/anurag/opt/anaconda3/lib/python3.7/site-packages (1.2.2)\n",
      "Requirement already satisfied: theano in /Users/anurag/opt/anaconda3/lib/python3.7/site-packages (from keras) (1.0.4)\n",
      "Requirement already satisfied: six in /Users/anurag/opt/anaconda3/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /Users/anurag/opt/anaconda3/lib/python3.7/site-packages (from keras) (5.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/anurag/opt/anaconda3/lib/python3.7/site-packages (from theano->keras) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/anurag/opt/anaconda3/lib/python3.7/site-packages (from theano->keras) (1.4.1)\n",
      "Requirement already satisfied: nltk in /Users/anurag/opt/anaconda3/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /Users/anurag/opt/anaconda3/lib/python3.7/site-packages (from nltk) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install keras\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Modeling Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "d46ba3fd-26f1-4635-b2f9-fca916ff3066",
    "_uuid": "21f3ccd962d1556dc2346699d45a29e9ef791367",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XvGfW6yECOIb",
    "outputId": "3f818c87-cc25-4cf7-cd09-2a530b458b7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/anurag/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/anurag/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/anurag/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/anurag/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/anurag/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/anurag/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "60326be1-82d1-4677-8ef8-da5b1eac475c",
    "_uuid": "adb496504ab8453ce2b4f91dd6e5f17cbdaf4f68",
    "colab_type": "text",
    "id": "erL7TVmYCOId"
   },
   "source": [
    "Let's load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "f-2g2ajRCOIe",
    "outputId": "06d8c71f-741e-4c9d-9d2b-ab90cfb07a2e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anurag/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Scoring Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "deb46a3c-6170-4323-8fac-2710662ae0b9",
    "_uuid": "62cd92e75f858aa7c97234e8267a64b00c6d04d0",
    "colab": {},
    "colab_type": "code",
    "id": "bBd9n3z9COIo"
   },
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    \n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4a37951-7a53-43b9-bb5a-0335f1259be3",
    "_uuid": "14ede2221105fb84bb6b2d3a85f9a1f483e8b124",
    "colab_type": "text",
    "id": "a81kkCgECOIq"
   },
   "source": [
    "### Let's Use LabelEncoder from scikit-learn to convert Genre labels to integers, 0, 1 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "d59a646d-7739-496c-814f-594d371d76eb",
    "_uuid": "19eb8c10f06df8e0f543ee12f794df5f88b0ff1a",
    "colab": {},
    "colab_type": "code",
    "id": "avnO-wf9COIq"
   },
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(train_df.Genre.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "65403e74-091f-43c4-9523-3e15d8a75a1e",
    "_uuid": "4ffd04f40d9e921673d06ad64e01b9a7395d8e76",
    "colab_type": "text",
    "id": "8OtK6PLsCOIs"
   },
   "source": [
    "### Before going further it is important that we split the data into training and validation sets. We can do it using \n",
    "#### `train_test_split` from the `model_selection` module of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_cell_guid": "ba8e606d-8dee-495e-8c3f-62aa916e9927",
    "_uuid": "b45676b121e2b719d355619e24cfed13d0d33f74",
    "colab": {},
    "colab_type": "code",
    "id": "tqXblO-mCOIt"
   },
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train_df.Script.values, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_cell_guid": "9e2fe6a9-8de0-4bbd-8264-f6b78e7993e2",
    "_uuid": "6c8659049537836fdf00d19d6d656630a306d217",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Ce_Eu4CrCOIu",
    "outputId": "042067e3-a5ad-4f5a-c727-0581878fdd86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1779,)\n",
      "(198,)\n"
     ]
    }
   ],
   "source": [
    "print (xtrain.shape)\n",
    "print (xvalid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3db70c26-d684-478a-bcd4-980ed6c6d65b",
    "_uuid": "794fb768f4a8e42c4be4f1dbb27144aae4d00c79",
    "colab_type": "text",
    "id": "unBlwkZ1COIx"
   },
   "source": [
    "# Building Basic Models\n",
    "\n",
    "### Let's start building our very first model. \n",
    "\n",
    "### Our very first model is a simple TF-IDF (Term Frequency - Inverse Document Frequency) followed by a simple Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_cell_guid": "b387f2af-11b1-455d-ad8d-320ed1005be3",
    "_uuid": "350d453dc982f494c3774dbdcf731d856546d611",
    "colab": {},
    "colab_type": "code",
    "id": "qnJ8aPthCOIx"
   },
   "outputs": [],
   "source": [
    "# Always start with these features. They work (almost) everytime!\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tfv = tfv.transform(test_df['Script'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_cell_guid": "4106bbd1-dc35-4dc2-bda0-3024d3c056d3",
    "_uuid": "3f5dd9ce043364fc61ba3a30298acd9cb72a2938",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NhMszJiuCOIz",
    "outputId": "d4060a49-dae8-4d78-e909-f752f83cdf8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anurag/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/anurag/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 2.477 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on TFIDF\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's predict on the entire test data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_preds = pd.DataFrame(columns = train_df.Genre.unique().tolist())\n",
    "test_set_preds.insert(0, 'File_name', test_df.File_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_preds[train_df.Genre.unique().tolist()] = clf.predict_proba(x_test_tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849, 22)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Action</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Family</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Musical</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>Music</th>\n",
       "      <th>History</th>\n",
       "      <th>Short</th>\n",
       "      <th>Film-Noir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>file_2300.txt</td>\n",
       "      <td>0.062685</td>\n",
       "      <td>0.0422617</td>\n",
       "      <td>0.0130921</td>\n",
       "      <td>0.00389762</td>\n",
       "      <td>0.127289</td>\n",
       "      <td>0.0614344</td>\n",
       "      <td>0.197159</td>\n",
       "      <td>0.0140578</td>\n",
       "      <td>0.0354991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0456963</td>\n",
       "      <td>0.00478094</td>\n",
       "      <td>0.00889435</td>\n",
       "      <td>0.0365217</td>\n",
       "      <td>0.0728687</td>\n",
       "      <td>0.0422514</td>\n",
       "      <td>0.00390061</td>\n",
       "      <td>0.202613</td>\n",
       "      <td>0.0102371</td>\n",
       "      <td>0.00661853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>file_809.txt</td>\n",
       "      <td>0.0618992</td>\n",
       "      <td>0.0426023</td>\n",
       "      <td>0.0129115</td>\n",
       "      <td>0.0038621</td>\n",
       "      <td>0.162966</td>\n",
       "      <td>0.064689</td>\n",
       "      <td>0.196208</td>\n",
       "      <td>0.014118</td>\n",
       "      <td>0.0339208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0407933</td>\n",
       "      <td>0.00475294</td>\n",
       "      <td>0.00878433</td>\n",
       "      <td>0.0327669</td>\n",
       "      <td>0.156604</td>\n",
       "      <td>0.0394729</td>\n",
       "      <td>0.00381307</td>\n",
       "      <td>0.0953924</td>\n",
       "      <td>0.0099409</td>\n",
       "      <td>0.00640487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>file_1383.txt</td>\n",
       "      <td>0.0986969</td>\n",
       "      <td>0.145076</td>\n",
       "      <td>0.0133924</td>\n",
       "      <td>0.00401209</td>\n",
       "      <td>0.0762054</td>\n",
       "      <td>0.0481369</td>\n",
       "      <td>0.137012</td>\n",
       "      <td>0.0143404</td>\n",
       "      <td>0.0357723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0462861</td>\n",
       "      <td>0.00495651</td>\n",
       "      <td>0.00920828</td>\n",
       "      <td>0.0343589</td>\n",
       "      <td>0.0532498</td>\n",
       "      <td>0.152186</td>\n",
       "      <td>0.00401394</td>\n",
       "      <td>0.0966585</td>\n",
       "      <td>0.0110366</td>\n",
       "      <td>0.00692348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>file_983.txt</td>\n",
       "      <td>0.0819403</td>\n",
       "      <td>0.0498307</td>\n",
       "      <td>0.0136413</td>\n",
       "      <td>0.00403657</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.063973</td>\n",
       "      <td>0.164306</td>\n",
       "      <td>0.014735</td>\n",
       "      <td>0.0365077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0468645</td>\n",
       "      <td>0.00501576</td>\n",
       "      <td>0.00937608</td>\n",
       "      <td>0.0367154</td>\n",
       "      <td>0.0640602</td>\n",
       "      <td>0.0481265</td>\n",
       "      <td>0.00406294</td>\n",
       "      <td>0.226756</td>\n",
       "      <td>0.0109584</td>\n",
       "      <td>0.00690064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>file_1713.txt</td>\n",
       "      <td>0.1548</td>\n",
       "      <td>0.110987</td>\n",
       "      <td>0.0142456</td>\n",
       "      <td>0.0041241</td>\n",
       "      <td>0.0726372</td>\n",
       "      <td>0.0500778</td>\n",
       "      <td>0.186908</td>\n",
       "      <td>0.0154501</td>\n",
       "      <td>0.037845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0464402</td>\n",
       "      <td>0.00508516</td>\n",
       "      <td>0.00966895</td>\n",
       "      <td>0.0722427</td>\n",
       "      <td>0.0491728</td>\n",
       "      <td>0.0499662</td>\n",
       "      <td>0.00415086</td>\n",
       "      <td>0.0891547</td>\n",
       "      <td>0.0112245</td>\n",
       "      <td>0.00706685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       File_name    Fantasy     Comedy      Drama      Sci-Fi    Romance  \\\n",
       "0  file_2300.txt   0.062685  0.0422617  0.0130921  0.00389762   0.127289   \n",
       "1   file_809.txt  0.0618992  0.0426023  0.0129115   0.0038621   0.162966   \n",
       "2  file_1383.txt  0.0986969   0.145076  0.0133924  0.00401209  0.0762054   \n",
       "3   file_983.txt  0.0819403  0.0498307  0.0136413  0.00403657     0.1036   \n",
       "4  file_1713.txt     0.1548   0.110987  0.0142456   0.0041241  0.0726372   \n",
       "\n",
       "    Thriller Adventure    Mystery     Action  ...     Horror      Family  \\\n",
       "0  0.0614344  0.197159  0.0140578  0.0354991  ...  0.0456963  0.00478094   \n",
       "1   0.064689  0.196208   0.014118  0.0339208  ...  0.0407933  0.00475294   \n",
       "2  0.0481369  0.137012  0.0143404  0.0357723  ...  0.0462861  0.00495651   \n",
       "3   0.063973  0.164306   0.014735  0.0365077  ...  0.0468645  0.00501576   \n",
       "4  0.0500778  0.186908  0.0154501   0.037845  ...  0.0464402  0.00508516   \n",
       "\n",
       "    Biography    Musical        War    Western       Music    History  \\\n",
       "0  0.00889435  0.0365217  0.0728687  0.0422514  0.00390061   0.202613   \n",
       "1  0.00878433  0.0327669   0.156604  0.0394729  0.00381307  0.0953924   \n",
       "2  0.00920828  0.0343589  0.0532498   0.152186  0.00401394  0.0966585   \n",
       "3  0.00937608  0.0367154  0.0640602  0.0481265  0.00406294   0.226756   \n",
       "4  0.00966895  0.0722427  0.0491728  0.0499662  0.00415086  0.0891547   \n",
       "\n",
       "       Short   Film-Noir  \n",
       "0  0.0102371  0.00661853  \n",
       "1  0.0099409  0.00640487  \n",
       "2  0.0110366  0.00692348  \n",
       "3  0.0109584  0.00690064  \n",
       "4  0.0112245  0.00706685  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_preds.to_excel('test_set_preds.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Starter Notebook - Movie Genre Classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
